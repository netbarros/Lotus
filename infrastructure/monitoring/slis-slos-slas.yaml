# ═══════════════════════════════════════════════════════════════════════════
# MAGICSAAS SYSTEM-∞ - SERVICE LEVEL INDICATORS, OBJECTIVES & AGREEMENTS
# Version: 1.0.0
# Based on: Google SRE Book - SLIs, SLOs, and SLAs
# ═══════════════════════════════════════════════════════════════════════════

# ═══════════════════════════════════════════════════════════════════════════
# SLI (Service Level Indicators) - What we measure
# ═══════════════════════════════════════════════════════════════════════════

service_level_indicators:
  # Availability SLIs
  - name: "System Availability"
    description: "Percentage of time the system is available and responding to requests"
    metric: "up{job='sofia-ai'} == 1"
    unit: "percent"
    measurement_window: "30d"

  - name: "API Availability"
    description: "Percentage of successful API requests (non-5xx responses)"
    metric: "(sum(rate(http_requests_total{status!~'5..'}[5m])) / sum(rate(http_requests_total[5m]))) * 100"
    unit: "percent"
    measurement_window: "30d"

  # Latency SLIs
  - name: "API Response Time (p95)"
    description: "95th percentile of API response time"
    metric: "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job='sofia-ai'}[5m]))"
    unit: "seconds"
    measurement_window: "30d"

  - name: "API Response Time (p99)"
    description: "99th percentile of API response time"
    metric: "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{job='sofia-ai'}[5m]))"
    unit: "seconds"
    measurement_window: "30d"

  - name: "Sofia AI Intention Processing Time (p95)"
    description: "95th percentile of intention processing time"
    metric: "histogram_quantile(0.95, rate(sofia_intention_processing_duration_seconds_bucket[5m]))"
    unit: "seconds"
    measurement_window: "30d"

  # Quality SLIs
  - name: "Error Rate"
    description: "Percentage of requests resulting in 5xx errors"
    metric: "(sum(rate(http_requests_total{status=~'5..'}[5m])) / sum(rate(http_requests_total[5m]))) * 100"
    unit: "percent"
    measurement_window: "30d"

  - name: "Sofia AI Generation Success Rate"
    description: "Percentage of successful SaaS generations"
    metric: "(sum(rate(sofia_generations_success_total[5m])) / sum(rate(sofia_generations_total[5m]))) * 100"
    unit: "percent"
    measurement_window: "30d"

  # Freshness SLIs
  - name: "Data Freshness"
    description: "Age of the most recently processed data"
    metric: "time() - max(sofia_last_data_update_timestamp_seconds)"
    unit: "seconds"
    measurement_window: "24h"

  # Correctness SLIs
  - name: "UX Validation Accuracy"
    description: "Percentage of UX validations that pass user acceptance"
    metric: "sofia_ux_validation_user_acceptance_rate"
    unit: "percent"
    measurement_window: "30d"

# ═══════════════════════════════════════════════════════════════════════════
# SLO (Service Level Objectives) - What we promise internally
# ═══════════════════════════════════════════════════════════════════════════

service_level_objectives:
  # Availability SLOs
  - name: "System Uptime"
    sli: "System Availability"
    target: "99.95"
    unit: "percent"
    measurement_window: "30d"
    error_budget: "0.05"  # 21.6 minutes per month
    priority: "P0"

  - name: "API Success Rate"
    sli: "API Availability"
    target: "99.9"
    unit: "percent"
    measurement_window: "30d"
    error_budget: "0.1"  # 43.2 minutes per month
    priority: "P0"

  # Latency SLOs
  - name: "API Latency (p95)"
    sli: "API Response Time (p95)"
    target: "0.200"  # 200ms
    unit: "seconds"
    measurement_window: "30d"
    priority: "P1"

  - name: "API Latency (p99)"
    sli: "API Response Time (p99)"
    target: "0.500"  # 500ms
    unit: "seconds"
    measurement_window: "30d"
    priority: "P1"

  - name: "Sofia AI Processing Time (p95)"
    sli: "Sofia AI Intention Processing Time (p95)"
    target: "300"  # 5 minutes
    unit: "seconds"
    measurement_window: "30d"
    priority: "P1"

  # Quality SLOs
  - name: "Low Error Rate"
    sli: "Error Rate"
    target: "0.1"  # <0.1% errors
    unit: "percent"
    measurement_window: "30d"
    priority: "P0"

  - name: "High Generation Success Rate"
    sli: "Sofia AI Generation Success Rate"
    target: "95"
    unit: "percent"
    measurement_window: "30d"
    priority: "P1"

  # Freshness SLOs
  - name: "Data Freshness"
    sli: "Data Freshness"
    target: "300"  # 5 minutes max staleness
    unit: "seconds"
    measurement_window: "24h"
    priority: "P2"

# ═══════════════════════════════════════════════════════════════════════════
# SLA (Service Level Agreements) - What we promise customers
# ═══════════════════════════════════════════════════════════════════════════

service_level_agreements:
  # Enterprise Tier SLA
  - tier: "Enterprise"
    commitments:
      - name: "System Uptime"
        target: "99.9"
        unit: "percent"
        measurement_window: "30d"
        credits:
          - threshold: "99.0"
            credit: "10"
          - threshold: "95.0"
            credit: "25"
          - threshold: "below_95"
            credit: "50"

      - name: "API Response Time (p95)"
        target: "0.300"  # 300ms
        unit: "seconds"
        measurement_window: "30d"

      - name: "Support Response Time"
        target: "1"  # 1 hour
        unit: "hours"
        measurement_window: "24h"
        priority: "P0/P1"

      - name: "Data Recovery Time Objective (RTO)"
        target: "1"
        unit: "hours"

      - name: "Data Recovery Point Objective (RPO)"
        target: "24"
        unit: "hours"

  # Professional Tier SLA
  - tier: "Professional"
    commitments:
      - name: "System Uptime"
        target: "99.5"
        unit: "percent"
        measurement_window: "30d"
        credits:
          - threshold: "99.0"
            credit: "10"
          - threshold: "95.0"
            credit: "25"

      - name: "API Response Time (p95)"
        target: "0.500"  # 500ms
        unit: "seconds"
        measurement_window: "30d"

      - name: "Support Response Time"
        target: "4"  # 4 hours
        unit: "hours"
        measurement_window: "24h"
        priority: "P0/P1"

  # Starter Tier SLA
  - tier: "Starter"
    commitments:
      - name: "System Uptime"
        target: "99.0"
        unit: "percent"
        measurement_window: "30d"

      - name: "API Response Time (p95)"
        target: "1.000"  # 1 second
        unit: "seconds"
        measurement_window: "30d"

      - name: "Support Response Time"
        target: "24"  # 24 hours
        unit: "hours"
        measurement_window: "48h"
        priority: "P1/P2"

# ═══════════════════════════════════════════════════════════════════════════
# ERROR BUDGET POLICY
# ═══════════════════════════════════════════════════════════════════════════

error_budget_policy:
  description: |
    Error budget is the amount of unavailability we can tolerate while still meeting our SLOs.
    When error budget is exhausted, we prioritize reliability over feature development.

  actions:
    - threshold: "100"  # Budget remaining
      action: "Normal feature development continues"

    - threshold: "50"  # 50% budget remaining
      action: "Review upcoming releases for reliability risks"

    - threshold: "25"  # 25% budget remaining
      action: |
        - Freeze non-critical feature launches
        - Focus on reliability improvements
        - Conduct incident review

    - threshold: "0"  # Budget exhausted
      action: |
        - STOP all feature launches
        - All hands on reliability
        - Root cause analysis required
        - Postmortem and corrective actions mandatory

# ═══════════════════════════════════════════════════════════════════════════
# MONITORING & ALERTING
# ═══════════════════════════════════════════════════════════════════════════

monitoring:
  slo_burn_rate_alerts:
    # Fast burn (1 hour window)
    - name: "SLO Fast Burn Rate"
      severity: "critical"
      window: "1h"
      threshold: "14.4"  # 14.4x burn rate = exhausts 30d budget in 50 hours
      action: "Page on-call engineer immediately"

    # Moderate burn (6 hour window)
    - name: "SLO Moderate Burn Rate"
      severity: "warning"
      window: "6h"
      threshold: "6"  # 6x burn rate = exhausts budget in 5 days
      action: "Create incident ticket, notify team"

    # Slow burn (3 day window)
    - name: "SLO Slow Burn Rate"
      severity: "info"
      window: "3d"
      threshold: "1"  # 1x burn rate = on track to exhaust budget
      action: "Review and plan reliability work"

  dashboards:
    - "SLO Dashboard - 30 day rolling window"
    - "Error Budget Dashboard - Current burn rate"
    - "SLA Compliance Dashboard - Customer-facing metrics"

# ═══════════════════════════════════════════════════════════════════════════
# REPORTING
# ═══════════════════════════════════════════════════════════════════════════

reporting:
  frequency: "monthly"
  recipients:
    - "engineering-leadership@softwarelotus.com.br"
    - "product-management@softwarelotus.com.br"
    - "customer-success@softwarelotus.com.br"

  metrics_included:
    - "SLI actual vs target"
    - "SLO compliance percentage"
    - "Error budget consumption"
    - "Incident summary"
    - "Corrective actions taken"
    - "Customer impact (if any)"
